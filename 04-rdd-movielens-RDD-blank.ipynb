{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.31.71.25:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVIES_CSV_FILE = \"ml-20m/movies.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_rdd = sc.textFile(MOVIES_CSV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_rdd = movies_rdd.filter(lambda x: x[0].isdigit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27278"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,Toy Story (1995),Adventure|Animation|Children|Comedy|Fantasy',\n",
       " '2,Jumanji (1995),Adventure|Children|Fantasy',\n",
       " '3,Grumpier Old Men (1995),Comedy|Romance',\n",
       " '4,Waiting to Exhale (1995),Comedy|Drama|Romance',\n",
       " '5,Father of the Bride Part II (1995),Comedy',\n",
       " '6,Heat (1995),Action|Crime|Thriller',\n",
       " '7,Sabrina (1995),Comedy|Romance',\n",
       " '8,Tom and Huck (1995),Adventure|Children',\n",
       " '9,Sudden Death (1995),Action',\n",
       " '10,GoldenEye (1995),Action|Adventure|Thriller']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_rdd.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 'movies_rdd' with each entry is a tuple (id, name, genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 'Toy Story (1995)', 'Adventure|Animation|Children|Comedy|Fantasy'],\n",
       " ['2', 'Jumanji (1995)', 'Adventure|Children|Fantasy'],\n",
       " ['3', 'Grumpier Old Men (1995)', 'Comedy|Romance'],\n",
       " ['4', 'Waiting to Exhale (1995)', 'Comedy|Drama|Romance'],\n",
       " ['5', 'Father of the Bride Part II (1995)', 'Comedy'],\n",
       " ['6', 'Heat (1995)', 'Action|Crime|Thriller'],\n",
       " ['7', 'Sabrina (1995)', 'Comedy|Romance'],\n",
       " ['8', 'Tom and Huck (1995)', 'Adventure|Children'],\n",
       " ['9', 'Sudden Death (1995)', 'Action'],\n",
       " ['10', 'GoldenEye (1995)', 'Action|Adventure|Thriller']]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_total(x):\n",
    "    a = x.split(',',1)\n",
    "    \n",
    "    b = a[1].rsplit(',',1)\n",
    "    return [a[0]] + b\n",
    "\n",
    "movies_rdd_tuple = movies_rdd.filter(lambda x: x[0].isdigit()).map(split_total)\n",
    "movies_rdd_tuple.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 'movies_title_rdd' with each entry is a tuple (id, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 'Toy Story (1995)'],\n",
       " ['2', 'Jumanji (1995)'],\n",
       " ['3', 'Grumpier Old Men (1995)'],\n",
       " ['4', 'Waiting to Exhale (1995)'],\n",
       " ['5', 'Father of the Bride Part II (1995)'],\n",
       " ['6', 'Heat (1995)'],\n",
       " ['7', 'Sabrina (1995)'],\n",
       " ['8', 'Tom and Huck (1995)'],\n",
       " ['9', 'Sudden Death (1995)'],\n",
       " ['10', 'GoldenEye (1995)']]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_title_rdd = movies_rdd_tuple.map(lambda x: [x[0]]+[x[1]])\n",
    "movies_title_rdd.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 'movies_genres_rdd' with each entry is a tuple (id, genre) (a movie ID can appear several times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 'Adventure'),\n",
       " ('1', 'Animation'),\n",
       " ('1', 'Children'),\n",
       " ('1', 'Comedy'),\n",
       " ('1', 'Fantasy'),\n",
       " ('2', 'Adventure'),\n",
       " ('2', 'Children'),\n",
       " ('2', 'Fantasy'),\n",
       " ('3', 'Comedy'),\n",
       " ('3', 'Romance')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test (x):\n",
    "    ID = x[0]\n",
    "    #print(ID)\n",
    "    genres = x[1]\n",
    "    #print(genres)\n",
    "    genres_split = genres.split('|')\n",
    "    #print(genres_split)\n",
    "    nb_genres = len(genres_split)\n",
    "    nouvelle_liste = []\n",
    "    for genre in genres_split:\n",
    "        nouvelle_liste.append((ID,genre))\n",
    "    return nouvelle_liste\n",
    "\n",
    "\n",
    "movies_genre_rdd = movies_rdd_tuple.map(lambda x: [x[0]]+[x[2]])\n",
    "movies_genre_rdd = movies_genre_rdd.flatMap(test)\n",
    "movies_genre_rdd.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the genres and count the number of times each genre appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adventure',\n",
       " 'Animation',\n",
       " 'Children',\n",
       " 'Comedy',\n",
       " 'Fantasy',\n",
       " 'Adventure',\n",
       " 'Children',\n",
       " 'Fantasy',\n",
       " 'Comedy',\n",
       " 'Romance']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_genres = movies_genre_rdd.map(lambda x: x[1])\n",
    "liste_genres.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Children', 1139),\n",
       " ('Fantasy', 1412),\n",
       " ('Romance', 4127),\n",
       " ('Drama', 13344),\n",
       " ('Action', 3520),\n",
       " ('Thriller', 4178),\n",
       " ('Horror', 2611),\n",
       " ('Sci-Fi', 1743),\n",
       " ('IMAX', 196),\n",
       " ('Documentary', 2471)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_times_genre = liste_genres.map(lambda x:(x,1)).reduceByKey(lambda a,b:a+b)\n",
    "nb_times_genre.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 'movie_year_rdd' with each entry is a tuple (id, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', '1995'],\n",
       " ['2', '1995'],\n",
       " ['3', '1995'],\n",
       " ['4', '1995'],\n",
       " ['5', '1995'],\n",
       " ['6', '1995'],\n",
       " ['7', '1995'],\n",
       " ['8', '1995'],\n",
       " ['9', '1995'],\n",
       " ['10', '1995']]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_id_year(x):\n",
    "    a = x.split(',',1)\n",
    "    print(a[1].split('(',1))\n",
    "    b = a[1].split('(',1)\n",
    "    date = b[1].split(')',1)[0]\n",
    "\n",
    "    return [a[0]] + [date]\n",
    "\n",
    "movie_year_rdd = movies_rdd.map(split_id_year)\n",
    "movie_year_rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATINGS_CSV_FILE = \"ml-20m/ratings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_rdd = sc.textFile(RATINGS_CSV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['userId,movieId,rating,timestamp']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_rdd = ratings_rdd.filter(lambda x: x[0].isdigit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,2,3.5,1112486027',\n",
       " '1,29,3.5,1112484676',\n",
       " '1,32,3.5,1112484819',\n",
       " '1,47,3.5,1112484727',\n",
       " '1,50,3.5,1112484580',\n",
       " '1,112,3.5,1094785740',\n",
       " '1,151,4.0,1094785734',\n",
       " '1,223,4.0,1112485573',\n",
       " '1,253,4.0,1112484940',\n",
       " '1,260,4.0,1112484826',\n",
       " '1,293,4.0,1112484703',\n",
       " '1,296,4.0,1112484767',\n",
       " '1,318,4.0,1112484798',\n",
       " '1,337,3.5,1094785709',\n",
       " '1,367,3.5,1112485980',\n",
       " '1,541,4.0,1112484603',\n",
       " '1,589,3.5,1112485557',\n",
       " '1,593,3.5,1112484661',\n",
       " '1,653,3.0,1094785691',\n",
       " '1,919,3.5,1094785621',\n",
       " '1,924,3.5,1094785598',\n",
       " '1,1009,3.5,1112486013',\n",
       " '1,1036,4.0,1112485480',\n",
       " '1,1079,4.0,1094785665',\n",
       " '1,1080,3.5,1112485375',\n",
       " '1,1089,3.5,1112484669',\n",
       " '1,1090,4.0,1112485453',\n",
       " '1,1097,4.0,1112485701',\n",
       " '1,1136,3.5,1112484609',\n",
       " '1,1193,3.5,1112484690']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_rdd.take(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 'ratings_rdd' with each entry is a tuple (userId,movieId,rating,timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', '2', '3.5', '1112486027'],\n",
       " ['1', '29', '3.5', '1112484676'],\n",
       " ['1', '32', '3.5', '1112484819'],\n",
       " ['1', '47', '3.5', '1112484727'],\n",
       " ['1', '50', '3.5', '1112484580'],\n",
       " ['1', '112', '3.5', '1094785740'],\n",
       " ['1', '151', '4.0', '1094785734'],\n",
       " ['1', '223', '4.0', '1112485573'],\n",
       " ['1', '253', '4.0', '1112484940'],\n",
       " ['1', '260', '4.0', '1112484826']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_rdd_tuple = ratings_rdd.map(lambda x: x.split(',')).cache()\n",
    "ratings_rdd_tuple.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean of all the notes using mean then meanApprox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3.5', '3.5', '3.5', '3.5', '3.5', '3.5', '4.0', '4.0', '4.0', '4.0']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_rating = ratings_rdd_tuple.map(lambda x: x[2])\n",
    "ratings_rating.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ratings_mean = ratings_rating.map(lambda x : float(x)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.525528564299375"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_meanApprox = ratings_rating.map(lambda x : float(x)).meanApprox(timeout=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.525528564299375"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_meanApprox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Various way to group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean of each movies using several methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **groupByKey()**\n",
    "* naive map-reduce approach: all keys are sent to reducers\n",
    "* high network I/O (shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('50', 4.334372207803259),\n",
       " ('112', 3.412573591253154),\n",
       " ('1196', 4.188202061218635),\n",
       " ('2692', 4.025309765693817),\n",
       " ('2959', 4.227123123722136),\n",
       " ('3030', 4.211716774374825),\n",
       " ('3153', 3.601982097186701),\n",
       " ('4306', 3.843613161516327),\n",
       " ('5039', 3.312160694896851),\n",
       " ('5040', 2.8283082077051924)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_gbkey = ratings_rdd_tuple.map(lambda x: (x[1],float(x[2]))).groupByKey().mapValues(lambda x: np.mean(list(x)))\n",
    "ratings_gbkey.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **reduceByKey()** \n",
    "* Warning function must be associative\n",
    "* see shuffle read/write for the I/O gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('50', 4.334372207803259),\n",
       " ('112', 3.412573591253154),\n",
       " ('1196', 4.188202061218635),\n",
       " ('2692', 4.025309765693817),\n",
       " ('2959', 4.227123123722136),\n",
       " ('3030', 4.211716774374825),\n",
       " ('3153', 3.601982097186701),\n",
       " ('4306', 3.843613161516327),\n",
       " ('5039', 3.312160694896851),\n",
       " ('5040', 2.8283082077051924)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_rbk = ratings_rdd_tuple.map(lambda x: (x[1],[float(x[2]),1]))\\\n",
    "                .reduceByKey(lambda a,b: [a[0]+b[0],a[1]+b[1]])\\\n",
    "                .mapValues(lambda x: x[0]/x[1])\n",
    "ratings_rbk.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **combineByKey()** ([ref to tutorial](https://github.com/mahmoudparsian/pyspark-tutorial/blob/master/tutorial/combine-by-key/spark-combineByKey.md))\n",
    "* variant of reduceByKey, using init map and reduce lambdas\n",
    "* equivalent to reduceByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('50', 4.334372207803259),\n",
       " ('112', 3.412573591253154),\n",
       " ('1196', 4.188202061218635),\n",
       " ('2692', 4.025309765693817),\n",
       " ('2959', 4.227123123722136),\n",
       " ('3030', 4.211716774374825),\n",
       " ('3153', 3.601982097186701),\n",
       " ('4306', 3.843613161516327),\n",
       " ('5039', 3.312160694896851),\n",
       " ('5040', 2.8283082077051924)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_cbk = ratings_rdd_tuple.map(lambda x: (x[1],float(x[2]))).combineByKey(lambda value: (value, 1),\n",
    "                            lambda x, value: (x[0] + value, x[1] + 1),\n",
    "                            lambda x, y: (x[0] + y[0], x[1] + y[1])\n",
    "                           ).mapValues(lambda x: x[0]/x[1])\n",
    "\n",
    "ratings_cbk.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **aggregateByKey()** ([ref to good doc](https://backtobazics.com/big-data/spark/apache-spark-aggregatebykey-example/))\n",
    "* 3 parameters:\n",
    "    * initial value for setting an accumulator for each key by partition\n",
    "    * computer accumulator on each entry for each key of the partition\n",
    "    * computer accumulators final value by key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 3.921239561324077),\n",
       " ('10', 3.430029305292191),\n",
       " ('100', 3.22138517618469),\n",
       " ('1000', 3.105911330049261),\n",
       " ('100003', 3.6666666666666665),\n",
       " ('100006', 2.5),\n",
       " ('100008', 3.4166666666666665),\n",
       " ('100010', 2.7954545454545454),\n",
       " ('100013', 3.2),\n",
       " ('100015', 2.0)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seq_op(accumulator, element):\n",
    "    if(accumulator[1] > element[1]):\n",
    "        return accumulator \n",
    "    else: \n",
    "        return element\n",
    " \n",
    " \n",
    "# Combiner Operation : Finding Maximum Marks out Partition-Wise Accumulators\n",
    "def comb_op(accumulator1, accumulator2):\n",
    "    if(accumulator1[1] > accumulator2[1]):\n",
    "        return accumulator1 \n",
    "    else:\n",
    "        return accumulator2\n",
    "    \n",
    " \n",
    "# Zero Value: Zero value in our case will be 0 as we are finding Maximum Marks\n",
    "zero_val = (0, 0)\n",
    "aggr_rdd = ratings_rdd_tuple.map(lambda t: (t[1], float(t[2])))\\\n",
    "                            .aggregateByKey((0,0),\n",
    "                            lambda x, value: (x[0] + value, x[1] + 1),\n",
    "                            lambda x, y: (x[0] + y[0], x[1] + y[1])\n",
    "                           ).mapValues(lambda x: x[0]/x[1])\n",
    "aggr_rdd.takeOrdered(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what are the best ten movies (with more than 50 votes) ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
